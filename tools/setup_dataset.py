import os
import glob
import json
import shutil
import argparse
from pathlib import Path

def setup_dataset():
    # 1. è¨­å®šå‘½ä»¤è¡Œåƒæ•¸è§£æ
    parser = argparse.ArgumentParser(description="Initialize Wan2.1/2.2 LoRA Training Dataset")
    parser.add_argument("--dir", type=str, required=True, help="Target training directory (e.g., /workspace/abbie)")
    args = parser.parse_args()

    # 2. è¨­å®šåŸºç¤è·¯å¾‘ (åŸºæ–¼è¼¸å…¥åƒæ•¸)
    base_dir = Path(args.dir).resolve()
    
    # å®šç¾©å­ç›®éŒ„èˆ‡æª”æ¡ˆè·¯å¾‘
    images_dir = base_dir / "images"
    cache_dir = base_dir / "cache"
    jsonl_path = base_dir / "metadata.jsonl"
    toml_path = base_dir / "dataset.toml"

    # è‡ªå‹•åµæ¸¬ Trigger Word (å–è³‡æ–™å¤¾åç¨±)
    trigger_word = base_dir.name
    
    print(f"ğŸš€ åˆå§‹åŒ–é–‹å§‹")
    print(f"ğŸ“‚ ç›®æ¨™å·¥ä½œç›®éŒ„: {base_dir}")
    print(f"ğŸ”‘ Trigger Word: {trigger_word}")

    # 3. æª¢æŸ¥ä¸¦å»ºç«‹ç›®éŒ„çµæ§‹ (å¦‚æœä¸å­˜å°±å»ºç«‹)
    if not base_dir.exists():
        print(f"ğŸ› ï¸  å»ºç«‹ä¸»ç›®éŒ„: {base_dir}")
        base_dir.mkdir(parents=True, exist_ok=True)

    if not images_dir.exists():
        print(f"ğŸ› ï¸  å»ºç«‹åœ–ç‰‡ç›®éŒ„: {images_dir}")
        images_dir.mkdir(parents=True, exist_ok=True)
    
    if not cache_dir.exists():
        print(f"ğŸ› ï¸  å»ºç«‹å¿«å–ç›®éŒ„: {cache_dir}")
        cache_dir.mkdir(parents=True, exist_ok=True)

    # 4. æœå°‹æ‰€æœ‰åœ–ç‰‡ (æ”¯æ´å¤šç¨®æ ¼å¼)
    extensions = ['*.jpg', '*.jpeg', '*.png', '*.webp', '*.bmp']
    image_files = []
    for ext in extensions:
        image_files.extend(list(images_dir.glob(ext)))
        image_files.extend(list(images_dir.glob(ext.upper())))
    
    image_files.sort()

    # å¦‚æœæ²’æœ‰åœ–ç‰‡ï¼Œåƒ…å»ºç«‹çµæ§‹å¾Œé€€å‡ºï¼Œæç¤ºç”¨æˆ¶ä¸Šå‚³
    if not image_files:
        print(f"âš ï¸  è­¦å‘Š: åœ¨ {images_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡ã€‚")
        print(f"â„¹ï¸  è«‹å°‡åœ–ç‰‡ä¸Šå‚³è‡³è©²ç›®éŒ„å¾Œï¼Œå†æ¬¡åŸ·è¡Œæ­¤è…³æœ¬ä»¥ç”Ÿæˆ metadata èˆ‡ tomlã€‚")
        
        # å³ä½¿æ²’åœ–ç‰‡ï¼Œæˆ‘å€‘ä¹Ÿå¯ä»¥å…ˆç”Ÿæˆä¸€å€‹åŸºæœ¬çš„ TOML æ¨¡æ¿ï¼Œæ–¹ä¾¿ç”¨æˆ¶æŸ¥çœ‹
        create_toml(toml_path, jsonl_path, cache_dir)
        return

    print(f"ğŸ“¸ æ‰¾åˆ° {len(image_files)} å¼µåœ–ç‰‡ï¼Œé–‹å§‹æ¨™æº–åŒ–è™•ç†...")

    # 5. é‡æ–°å‘½åä¸¦å»ºç«‹ JSONL å…§å®¹
    jsonl_data = []
    rename_map = []
    
    for idx, img_path in enumerate(image_files, start=1):
        ext = img_path.suffix.lower()
        new_filename = f"{idx}{ext}"
        new_path = images_dir / new_filename
        
        rename_map.append((img_path, new_path))
        
        # æº–å‚™ JSONL æ¢ç›® (ä½¿ç”¨çµ•å°è·¯å¾‘)
        entry = {
            "image_path": str(new_path),
            "caption": f"A caption for {trigger_word}" 
        }
        jsonl_data.append(entry)

    # åŸ·è¡Œå®‰å…¨é‡æ–°å‘½å (Temp renaming logic)
    temp_map = []
    for old_p, new_p in rename_map:
        if old_p != new_p:
            temp_name = old_p.parent / f"temp_{old_p.name}"
            try:
                shutil.move(str(old_p), str(temp_name))
                temp_map.append((temp_name, new_p))
            except Exception as e:
                print(f"âŒ ç§»å‹•å¤±æ•— {old_p}: {e}")
        else:
            temp_map.append((old_p, new_p))
            
    for temp_p, new_p in temp_map:
        try:
            shutil.move(str(temp_p), str(new_p))
        except Exception as e:
            print(f"âŒé‡æ–°å‘½åå¤±æ•— {temp_p}: {e}")

    # 6. å¯«å…¥ metadata.jsonl
    try:
        with open(jsonl_path, 'w', encoding='utf-8') as f:
            for entry in jsonl_data:
                f.write(json.dumps(entry) + '\n')
        print(f"âœ… å·²å»ºç«‹ Metadata: {jsonl_path}")
    except Exception as e:
        print(f"âŒ å¯«å…¥ JSONL å¤±æ•—: {e}")

    # 7. ç”Ÿæˆ dataset.toml
    create_toml(toml_path, jsonl_path, cache_dir)

    print("ğŸ‰ åˆå§‹åŒ–å®Œæˆï¼")

def create_toml(toml_path, jsonl_path, cache_dir):
    """å°‡ TOML ç”Ÿæˆé‚è¼¯ç¨ç«‹å‡ºä¾†"""
    toml_content = f"""[general]
resolution = [960, 544]
batch_size = 1
enable_bucket = true
bucket_no_upscale = false

[[datasets]]
image_jsonl_file = "{str(jsonl_path)}"
cache_directory = "{str(cache_dir)}"
num_repeats = 10
"""
    try:
        with open(toml_path, 'w', encoding='utf-8') as f:
            f.write(toml_content)
        print(f"âœ… å·²æ›´æ–°è¨­å®šæª”: {toml_path}")
    except Exception as e:
        print(f"âŒ å¯«å…¥ TOML å¤±æ•—: {e}")

if __name__ == "__main__":
    setup_dataset()
